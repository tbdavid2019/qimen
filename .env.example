# LLM 配置
# 選擇 LLM 提供商：openai, anthropic, ollama, groq, qwen
LLM_PROVIDER=openai

# API Key（根據提供商填入對應的 Key）
LLM_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# 模型名稱（可選，會使用預設模型）
LLM_MODEL=gpt-4o-mini

# 自定義 API 基礎 URL（可選，用於自建服務或代理）
# LLM_BASE_URL=https://api.openai.com/v1

# Discord webhook URL（可選）
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/YOUR_WEBHOOK_ID/YOUR_WEBHOOK_TOKEN

# 應用端口
PORT=3000

# 支援的 LLM 配置範例：

# OpenAI 配置
# LLM_PROVIDER=openai
# LLM_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# LLM_MODEL=gpt-4o-mini

# Anthropic Claude 配置
# LLM_PROVIDER=anthropic
# LLM_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# LLM_MODEL=claude-3-haiku-20240307

# 本地 Ollama 配置
# LLM_PROVIDER=ollama
# LLM_API_KEY=not_required
# LLM_MODEL=llama3.1:latest
# LLM_BASE_URL=http://localhost:11434/v1

# Groq 配置
# LLM_PROVIDER=groq
# LLM_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# LLM_MODEL=mixtral-8x7b-32768

# 阿里通義千問配置
# LLM_PROVIDER=qwen
# LLM_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# LLM_MODEL=qwen-turbo
